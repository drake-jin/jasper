<!DOCTYPE html>
<html>
<head>
    <!-- [[! Document Settings ]] -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- [[! Page Meta ]] -->
    <title>(스터디) 하둡.araboza - 5</title>
    <meta name="description" content="데이터공작소 - 데이터 분석은 잘 못하지만, 데이터 분석할 수 있게 도와드리겠어요!" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/assets/images/favicon.ico" >

    <!-- [[! Styles'n'Scripts ]] -->
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css"
          href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css" />

    <!-- [[! highlight.js ]] -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- [[! Ghost outputs important style and meta data with this tag ]] -->
        <link rel="canonical" href="/" />
    <meta name="referrer" content="origin" />
    <link rel="next" href="/page2/" />

    <meta property="og:site_name" content="데이터공작소" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="데이터공작소" />
    <meta property="og:description" content="데이터 분석은 잘 못하지만, 데이터 분석할 수 있게 도와드리겠어요!" />
    <meta property="og:url" content="/" />
    <meta property="og:image" content="/assets/images/cover1.jpg" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="데이터공작소" />
    <meta name="twitter:description" content="데이터 분석은 잘 못하지만, 데이터 분석할 수 있게 도와드리겠어요!" />
    <meta name="twitter:url" content="/" />
    <meta name="twitter:image:src" content="/assets/images/cover1.jpg" />

    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Website",
    "publisher": "Finding The Way Home",
    "url": "/",
    "image": "/assets/images/cover1.jpg",
    "description": "데이터 분석은 잘 못하지만, 데이터 분석할 수 있게 도와드리겠어요!"
}
    </script>

    <meta name="generator" content="Jekyll 3.0.0" />
    <link rel="alternate" type="application/rss+xml" title="데이터공작소" href="/feed.xml" />


</head>
<body class="home-template nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        <li class="nav-home " role="presentation"><a href="/">Home</a></li>
        <li class="nav-about " role="presentation"><a href="/about">About</a></li>
        <li class="nav-fables " role="presentation"><a href="/tag/fables">Fables</a></li>
        <li class="nav-speeches " role="presentation"><a href="/tag/speeches">Speeches</a></li>
        <li class="nav-fiction " role="presentation"><a href="/tag/fiction">Fiction</a></li>
        <li class="nav-author " role="presentation"><a href="/author/casper">Author</a></li>
    </ul>
    <a class="subscribe-button icon-feed" href="/feed.xml">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        <!-- [[! Everything else gets inserted here ]] -->
        <!-- < default -->

<!-- The comment above "< default" means - insert everything in this file into -->
    <!-- the [body] of the default.hbs template, which contains our header/footer. -->

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->



<header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        
        
    </nav>
</header>

<main class="content" role="main">

    <article class="">

        <header class="post-header">
            <h1 class="post-title">(스터디) 하둡.araboza - 5</h1>
            <section class="post-meta">
            <!-- <a href='/'>drakejin</a> -->
            <time class="post-date" datetime="2017-05-08">08 May 2017</time>
                <!-- [[tags prefix=" on "]] -->
                 
                on 
                
                    
                       <a href='/tag/hadoop'>Hadoop</a>,
                       
                
                    
                       <a href='/tag/hdfs'>Hdfs</a>,
                       
                
                    
                       <a href='/tag/mapreduce'>Mapreduce</a>
                       
                
                
            </section>
        </header>

        <section class="post-content">
            
            <p>[데이터공작소]하둡.araboza - 5 에서 진행했던 소스를 좀 더 자세히 살펴보는 글입니다. 이번 챕터를 통해 맵 리듀스에 대해 자세히 알아보는 시간을 갖도록 합니다.</p>

<h2 id="chapter-05">Chapter 05</h2>
<p>Chapter04의 WordCount소스에 사용된 MapReduce소스에 대해서 분석해보는 챕터입니다.
 - <a href="https://autofei.wordpress.com/2010/06/27/oreilly-hadoop-the-definitive-guide-06-2009/">하둡의 작동방법에 대해 상세히 나와있음 </a></p>

<p><img src="/assets/posts/res/2017-05-08/mapreduce.jpg" alt="mapreduce" />
<img src="/assets/posts/res/2017-05-08/mapreduce-process.png" alt="mapreduce-process" /></p>

<h2 id="section">차례</h2>
<ol>
  <li>맵퍼</li>
  <li>맵리듀스의 기본 자료형</li>
  <li>입력포맷</li>
  <li>컴바이너</li>
  <li>셔플링과 소팅</li>
  <li>리듀스</li>
  <li>출력포맷</li>
  <li>카운터</li>
  <li>MRUnit과 메이븐</li>
  <li>잡 트래커와 웹 인터페이스</li>
</ol>

<h2 id="section-1">맵 리듀스의 맵퍼</h2>

<p>``` java
class Mapper{</p>

<div class="highlighter-rouge"><pre class="highlight"><code>public void setup(Mapper.Context context);
/*
map 메소드에서 필요 리소스를 할당하는 역할을 합니다. map의 선행작업을 여기서 수행할 수 있습니다.
분산캐시를 오픈하거나 파일을 미리오픈하거나 여기서 할 수 있습니다.
*/    

public void cleanup(Mapper.Context context);
/*
setup클래스의 반대 역할입니다. 할당한 리소스를 해제하는 역할을 합니다. 함수의 호출이 완료되면, 마지막으로 한번 호출됩니다.
예를들어 setup에서 할당한 자원을 cleanup에서 해제하는것이 일반적인 사용모델입니다.
*/

public void run(Context context) throws IOException InterruptedException{
    setup(context);
    while(context.nextKeyValue()){
        map(context.getCurrentKey(), context.getCurrentValue(),context)
    }
    cleanup(context);
}
/*
Mapper의 전체 구동함수에 해당하며 이 함수를 오버라이드 할 일은 거의 없을것이다.
setup메서드의 작업이 끝나야지 run메서드가 수행된다.
*/
</code></pre>
</div>

<p>}
```</p>

<h3 id="k1v1">맵퍼의 입력 K1,V1</h3>
<p>맵의 입력에서 가장 중요한 부분은 어떤 입력 포맷을 사용하였는가이다.
 - 텍스트 라인 하나가 하나의 레코드에 해당
 - 해당 라인의 파일오프셋(파일 처음부터의 위치)가 키 값이 된다. (키 타입은 LongWritable)
 - 해당 라인의 전체가 Value가 됩니다. Value Type은 Text가 됩니다.
맵의 입력에 사용되는 입력포맷은  TextInputFormat 이외에도 [KeyValueTextInputFormat, SequenceFileInputFormat]등이 있습니다.</p>

<h3 id="k3v3">맵퍼의 출력 K3,V3</h3>
<p>맵의 출력 레코드들의 타입들이 전체 하둡 잡의 출력 타입들과 다르다면 Job클래스의 다음 두 메서드 호출을 통해서 프레임 워크에 알려야 합니다.</p>

<blockquote>
  <p>job.setMapOutputKeyClass
  job.setMapOutputValueClass</p>
</blockquote>

<p>워드카운트 에서는 맵의 출력타입과 리듀스의 출력타입이 일치했기 때문에 위의 두 메소드를 호출할 필요기 없었습니다.</p>

<p>간혹 맵 출력만 필요하고 리듀스는 아예 필요로 하지 않는다면 리듀스 태스크의 수를 0으로 지정하면 된다. 그러면 지정한 하둡잡의 출력 디렉토리에
맵의 출력물들이 바로 저장되게 된다.</p>

<blockquote>
  <p>저장되는 파일 이름 형식은
part-r-xxxx =&gt; part-m-xxxx가 된다.</p>
</blockquote>

<h3 id="identity-mapper--reducer">아이덴티티 맵퍼,리듀서 (Identity Mapper &amp; Reducer)</h3>
<p>작업중에는 맵이나 리듀스가 필요없는것들도 있다. 이럴 때 사용하는게 아이덴티티 맵퍼나 리듀서이다.
&gt; 아이덴티티 매퍼와 아이덴티티 리듀서는 주어진 입력 레코드(키,벨류)를 그대로 출력레코드로 내보내는 단순한 맵 클래스와 리듀스 클래스.</p>

<h2 id="mapreduce----">MapReduce의 기본 자료형 및 변수들</h2>

<p><img src="/assets/posts/res/2017-05-08/wrapping-variables.png" alt="wrapping variables" /></p>

<h3 id="writable-">Writable 인터페이스</h3>
<ul>
  <li>기본적으로 이 인터페이스는 직렬화/역직렬화(Serialization/Deserialization) 을 구현하는데 사용되는 메소드들을 갖고 있다.</li>
  <li>하둡 특성상 키/벨류 레코드가 디스크에 저장되거나 네트워크를 타고 전달되어야 하기 때문에 이런 인터페이스가 필요하다.</li>
  <li>하둡은 RPC(Remote Procedure Call)을 이용해서 클러스터 내의 노드들 간에 통신합니다. 이 경우에도 Writable인터페이스를 사용하여 통신합니다.</li>
</ul>

<p>``` java 
public class ItemFreq implements Writable{
    private String item;
    private Long freq;</p>

<div class="highlighter-rouge"><pre class="highlight"><code>@Override
public void write(DataOutput out)throws IOException{
    //write는 직렬화(Serialization)에 사용되는 메서드 이다. 주어진 스트림 내부 데이터를 차례로 저장하는 일을 수행하며, 저장된 데이터들만 보고 원래 상태가 복구될 수 있게 필요한 모든 정보를 저장한다.
    WritableUtils.wrtieString(out, item);
    // 먼저out객체에 item을 작성하고
    out.writeLong(freq);
    // 그 다음 out 객체에 값을 작성한다.
}
@Override
public void readFields(DataInput in) throws IOException{
    // readFields 는 역직렬화(Deserialization)에 사용되는 메서드 이다. write에서 저장했던 순서 ㄱ대로 차례로 저장했던 데이터를 꺼내어 객체의 마지막 상태로 원상 복구하는 역할을 수행한다.
    item = WritableUtils.readString(in);//in의 item문자열을 읽는다.
    freq = in.readLong(); // freq를 읽는다.
}
//... 생략
</code></pre>
</div>

<p>}
```</p>

<h3 id="writablecomparable-">WritableComparable 인터페이스</h3>
<ul>
  <li>WritableComparable 은 Writable 에서 제공되는 메소드들에다가 객체들간의 비교를 가능하게 해주기 위해 Comparable인터페이스가 추가된 인터페이스 입니다.</li>
  <li>하둡에서 맵과 리듀스에서 사용되는 키들은 소팅이 가능해야 하기 때문에 이런 인터페이스가 필요합니다.</li>
  <li>Compareble인터페이스에는 compareTo라는 메소드 하나가 존재하며 이는 결국지금 객체와 인자로 들어온 객체들을 비교하여 둘 사이의 순서를 정해주는 역할을 합니다.</li>
</ul>

<p>``` java
 // Writable인터페이스에서 compareTo 메서드가 추가된것 말고 다른게 없음.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>@Override
public int compareTo(ItemFreq o) {
    int result = item.compareTo(o.item);
    if(0 = result){
        result = (int) (freq-(o.freq));
    }
    return result;
}
</code></pre>
</div>

<p>```</p>

<h2 id="mapreduce-wapping-">MapReduce의 Wapping 자료형</h2>

<table>
  <thead>
    <tr>
      <th>Wrapping 변수</th>
      <th>원본</th>
      <th>반환 방법</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Text</td>
      <td>String</td>
      <td>.toString()</td>
    </tr>
    <tr>
      <td>IntWritable</td>
      <td>int</td>
      <td>.get()</td>
    </tr>
    <tr>
      <td>LongWritable</td>
      <td>Long, long</td>
      <td>.get()</td>
    </tr>
    <tr>
      <td>FloatWrtiable</td>
      <td>Floa, float</td>
      <td>.get()</td>
    </tr>
    <tr>
      <td>BooleanWritable</td>
      <td>Boolean, boolean</td>
      <td>.get()</td>
    </tr>
    <tr>
      <td>ArrayWritable</td>
      <td>[] , ArrayList</td>
      <td>x</td>
    </tr>
    <tr>
      <td>NullWritable</td>
      <td>null</td>
      <td>x</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>이외 제공되는 타입을 보려면 http://org.apache.hadoop.io를 참조하길…</li>
</ul>

<h2 id="section-2">입력 포맷의 역할</h2>
<p><img src="/assets/posts/res/2017-05-08/input-format.png" alt="input format " />
 - job.setInputFormatClass() 에 해당되는 내용.</p>

<h3 id="textinputformat">TextInputFormat</h3>
<ul>
  <li>FileInutFormat을 상속함</li>
  <li>텍스트 파일 대상이며 .gz 로 압축된 것도 처리가능하다.</li>
  <li>라인 하나(\n, \r)가 하나의 입력 레코드에 해당됨.</li>
  <li>한 레코드(라인)에서 키는 라인의 파일 오프셋(파일 선부에서부터) 타입은LongWritable이다.</li>
  <li>한 레코드에서 라인 전체 스트링이 되며 타입은 text이다.</li>
</ul>

<h3 id="keyvaluetextinputformat">KeyValueTextInputFormat</h3>
<ul>
  <li>Keyvaluetextinputformat = TextInputFormat 기본적으로는 같다.</li>
  <li>차이점은 하나의 레코드를 해석할 때 키와 벨류사이에 TAB문자와 같은 문자열을 분리자로 인지 하는지 안하는지에 대한 차이가 있습니다.</li>
  <li>TAB 문자열 = \r</li>
</ul>

<h3 id="sequencefileinputformat">SequenceFileInputFormat</h3>
<ul>
  <li>하둡의 고유 파일 폼냇은 시퀀스파일</li>
  <li>이 때 사용되는 기본 클래스가 바로 이 클래스</li>
  <li>해당 파일이 생성 될 때 사용된 키와 밸류 타입을 사용해야 한다.</li>
  <li>하지만 TextInputFormat 과 다른점은 LongWritable 과 Text로 고정된것이 아니기 때문에 어떤 Key와 Value로써 사용가능합니다.</li>
  <li>이 포맷은 맵 파일을 읽는데도 사용할 수 있습니다.</li>
  <li>디렉토리로 값을 줘도 읽을 수 있으며, 디렉토리로 값을 줄 때 맵 파일의 형태를 먼저 읽고 그 다음에 시퀀스 파일을 로드 합니다.</li>
</ul>

<h3 id="multipleinputs">MultipleInputs</h3>
<ul>
  <li>지금까지 입력포맷은 잡에 하나의 맵만 존재하는 형태였다. 하지만 입력포맷이 다른 경우에는 어떻게 되는가?</li>
  <li>Multipleinputs클래스를 사용하여 공통된 키를 묶어서 조인을 수행할 수 있다.</li>
</ul>

<p>``` java
    public static void addInputPath(
        JobConf conf,  // 별도의 job class파일을 이용해도 된다. 
        Path path, //hdfs상의 파일 위치
        Class&lt;? extends InputFormat&gt; inputFormatClass,
        Class&lt;? extneds Mapper&gt; mapperClass
    )</p>

<p>```</p>

<h3 id="section-3">그 외 입력폼맷</h3>
<ul>
  <li>CombineFileInputFormat</li>
  <li>NLineInputFormat</li>
</ul>

<h3 id="section-4">맵 태스크 수의 결정 방식</h3>
<ul>
  <li>입력파일을 처리하기 위해 필요한 맵 태스크의 수는 프레임워크가 알아서 결정한다.</li>
  <li>입력포맷이 주어진 입력 파일을 처리하는데 몇 개의 맵 태스크가 필요한지 결헝한다.</li>
  <li>입력포맷은 getSplits라는 메소드를 갖고 있는데 이는 주어진 모든 입력 파일들을 조각(InputSplit이라 한다.)으로 나눠서 그 조각들의 리스트를 리턴합니다.</li>
  <li>이 조각마다 맵 태스크가 하나씩 할당된다.</li>
</ul>

<ol>
  <li>리듀스가 하나일경우</li>
</ol>

<p><img src="/assets/posts/res/2017-05-08/one-reduce.png" alt="one reduce" /></p>

<ol>
  <li>리듀스가 두개일 경우</li>
</ol>

<p><img src="/assets/posts/res/2017-05-08/two-reduce.png" alt="two reduce" /></p>

<ol>
  <li>리듀스가 없을 경우</li>
</ol>

<p><img src="/assets/posts/res/2017-05-08/none-reduce.png" alt="none reduce" /></p>

<h3 id="getsplits----">getSplits의 파일 조각 나누는 방식</h3>

<blockquote>
  <p>(맵 태스크 수) = (입력파일 수) * (데이터블록) or (gzip 등 압축된 파일 수)</p>
</blockquote>

<ol>
  <li>입력파일의 수
    <ul>
      <li>기본적으로 입력 파일의 수가 중요한 요소가 된다.</li>
      <li>맵 태스크의 수는 이보다 더 작아질 수는 없다.</li>
    </ul>
  </li>
  <li>입력파일의 크기
    <ul>
      <li>데이터 블록으로 구성될 탠대 맵 테스크는 하나의 블록마다 할당된다.</li>
      <li>결국 하나의 블록이 하나의 Input Split이 된다.</li>
    </ul>
  </li>
  <li>입력포맷의 지능
    <ul>
      <li>gzip 등으로 압축되어있으면 전체 파일을 블록수와 관계없이 하나의 맵태스크로 지정함</li>
    </ul>
  </li>
</ol>

<h3 id="section-5">입력포맷의 역할</h3>
<ul>
  <li>입력파일을 InputSplit으로 나누기</li>
  <li>하나의 InputSplit내의 레코드들을 읽는 방법 제공</li>
</ul>

<h2 id="combiner">컴바이너 (Combiner)</h2>
<ul>
  <li>미니 리듀서 혹은 로컬 리듀서라고 부른다.</li>
  <li>맵 태스크의 출력에 리듀스 코드 먼저 적용해서 리듀스로 넘어가야 하는 데이터의 크기를 줄이는 역할 담당.</li>
  <li>컴바이너 적용 가능 모델 :잡의 성격마다 다르지만 작업의 순서를 달리해도 최종 결과물이 같은 잡일 경우에만.</li>
  <li>컴바이넌 적용 가능 모델이라면 리듀스 클래스를 그대로 컴바이너로 가져가는걸 추천한다.</li>
  <li>셔플링과 소팅부분에서는 컴바이너를 여러번 적용 시키는 모델이 존재한다.</li>
  <li>WordCount의 경우 Combiner의 특성을 가지고 있기 때문에 main함수에서 리듀스 클래스를 그대로 컴바이너로 지정할 수 있습니다.</li>
</ul>

<h2 id="shuffling-and-sorting">셔플링과 소팅(Shuffling and Sorting)</h2>
<p>맵 리듀스에서 자동으로 해주는 내부동작이다. 맵 태스크와 리듀스 태스크를 이해하기위해 이해하고 넘어가야 할 부분</p>

<h3 id="to----">파티셔너 to 레코드 어떻게 리듀스로 보내는가.</h3>
<ol>
  <li>결과 레코드의 키값을 해싱한다.</li>
  <li>해싱된 값을 리듀스 태스크의 수로 나눈다.</li>
  <li>해싱된 레코드가 어느 태스크로 갈지 결졍된다.(같은 키를 갖는 레코드들은 같은 리듀스 태스크로 보내지게 된다.)</li>
  <li>1번~3번 동작을 수행하는것이 바로 파티셔너(partitioner)라 부른다.
    <ul>
      <li>맵 태스크가 새로운 Key/Value를 출력하면 이는 궁극적으로 특정 리듀스 태스크로 보내져야 한다.</li>
      <li>자신만의 파티셔너를 정의할 수 있지만, 기본적으로 사용되는 파티셔너의 클래스이름은 HashPartitioner</li>
    </ul>
  </li>
</ol>

<p>``` java
// HashPartitioner&lt;K,V&gt;.class</p>

<p>public class HashPartitioner&lt;K, V&gt; extends Partitioner&lt;K, V&gt;{
    /** use {@link Object#hashCode()} to partition. **/ 
    public int getPartition(K key,V value, int numReduceTasks){
        return (key.hashcode() &amp; Integer.MAX_VALUE) % numReduceTasks;//파티션 번호에 해당한다.
    }
}</p>

<p>```</p>

<ul>
  <li>파티션 번호 : 위 코드를 보면 알 수 있듯이 주어진 키의 해시값을 얻어낸 다음에 그것을 리듀스 태스크의 수(Job 클래스의 numReduceTasks메소드로 지정한 값)로 나눈 나머지를 리턴하고 있다.</li>
  <li>파티셔너는 맵 테스크에서 나온 ㅊㄹ력레코드를 보고 어느 리듀스 태스크로 보낼지 결정해주는것이 파티셔너 입니다.</li>
</ul>

<h3 id="section-6">맵 출력 버퍼링</h3>
<ol>
  <li>맵에서 출력된 레코드 들은 파티셔너(Partitioner) 클래스를 통해 파티션 번호를 알아낸다.</li>
  <li>리듀스로 바로 가지 않고 메모리 버퍼에 씌어졌다가 메모리 버퍼가 차면 디스크에 레코드가 써집니다.</li>
  <li>맵 태스크가 종료될때까지 1번과 2번 과정을 반복합니다.</li>
  <li>종료시에는 디스크로 존재하던 파일들을 모두 모아서 하나의 파일로 병합합니다.(4번의 과정은 모든 맵 태스크마다 이루어지게 됩니다.)</li>
  <li>리듀스 태스크들은 병합된 결과 레코드 파일에서 각기 자신에게 해당하는 파티션의 데이터를 읽어 갑니다.</li>
  <li>M개의 맵퍼와 N개의 리듀서가 존재한다면 M*N개의 네트워크 커넥션이 맺어지게 됩니다.</li>
  <li>M*N개의 커넥션의 네트워크를 통해 리듀서 자신에게 해당되는 데이터를 복사해 갑니다.</li>
</ol>

<ul>
  <li>M*N개의 커넥션에서 리듀서 자신에게 해당되는 데이터를 복사해갈 때 데이터가 크다면 병목지점이 발생하게 된다.</li>
  <li>성능에 있어 랜덤쓰기와 순차쓰기의 차이때문에 맵의 결과를 임시적으로 메모리 버퍼에 저장하는 방식을 이용한다.  (잦은 파일 입출력 방지를 위해)</li>
</ul>

<h3 id="section-7">셔플링</h3>

<p><img src="/assets/posts/res/2017-05-08/shuffling-sorting.png" alt="Shuffling &amp; sorting" /></p>

<ul>
  <li>셔플링 : 맵 태스크가 종료되면 그때 리듀스 태스크들이 자신에게 해당하는 파티션의 데이터만 읽어가게 되는데 이때는 RPC등을 통하는 것이 아니라 그냥 HTTP를 통해 읽습니다. 이 과정을 셔플링이라한다.</li>
  <li>셔플링이 섞는 과정인줄알았는데 알고보니 단순 데이터 복사.</li>
  <li>송수신 시 에러발생을 감지하기위해 CRC(Cycle Redundancy Check)체크썸 정보(4Byte)가 마지막에 별도로 전송된다. 리듀스의 데이터 읽기용말고 일반적으로 데이터 송수신에도 사용된다.</li>
</ul>

<h3 id="section-8">모니터링 툴들</h3>
<ul>
  <li>Ganglia: 하둡전용이 아닌 일반적인 클러스터와 같은 분산화경용 모니터링 시스템</li>
  <li>Amabari : 하둡 클러스터 모니터링, 하둡클러스터 설치와 관리, 여러가지 기능을 지원하는 종합적인 툴의 성격</li>
  <li>Puppet : 환경 설정관리, 파일의 복사 성공여부를 조회하고 관리할 수 있습니다.</li>
</ul>

<h3 id="section-9">소팅</h3>
<ul>
  <li>spill을 합병할 때 처럼 파일들의 수를 이정한 수 밑으로 유지하려 한다. 이 때도 io.sort.factor파라미터 값을 사용한다.</li>
  <li>맵 태스크들에서 자신의 파티션 데이터들을 가져왔으면 이 데이터들을 하나로 병합한다.</li>
  <li>병합된 데이터를 키를 바탕으로 소팅한다.(GroupingComparator)라는 게 이용된다. 이것은 리듀스 태스크들로 모인 레코드들의 키를 정렬하는 역할을 한다.</li>
  <li>소팅이 끝나면 소팅된 레코드들을 전체적으로 스캔하면서 레코드들을 그룹핑한다.</li>
  <li>이는 하나의 리듀스 입력 레코드를 만드는 것이다.</li>
  <li>한 그룹으로 묶여진 레코드들 간의 순서를 정하기 위해서 SortComparator 라는것을 사용한다.</li>
</ul>

<h2 id="section-10">리듀스 클래스</h2>
<ul>
  <li>Reducer클래스를 보면 run, setup, cleanup이란 메소드들을 가지고 있으며 하는 역할도 맵 클래스에서 하는 역할과 비슷하다.</li>
</ul>

<h3 id="section-11">리듀스의 입력</h3>
<ul>
  <li>셔플링과 소팅을 통해 리듀스의 입력은 모든 맵 태크들의 출력 레코드가 합쳐져서 만들어진것.</li>
  <li>맵 태스크 출력 레코드들의 셔플링과 소팅이 완료되면 리듀스의 입력 레코드는 완성됨</li>
</ul>

<h3 id="section-12">리듀스의 출력</h3>
<ul>
  <li>출력레코드는 hdfs상에서 저장된다.</li>
</ul>

<h3 id="identity-reducer">아이덴티티 리듀서(Identity Reducer)</h3>
<ul>
  <li>입력으로 들어온 레코드를 그대로 다시 출력해주는 역할을 한다.</li>
  <li>모든 리듀서의 기본 클래스는 에이덴티티 리듀서로 구현되어있다.</li>
  <li>아이덴티티 리듀서는 밸류 리스트를 다시 리스트로 내보내는것이 아닌 for루프 돌면서 각기 하나의 값을 하나의 레코드로 출력한다.</li>
  <li>밸류 리스트에 N개의 원소가 있었다면, N 개의 키/밸류 레코드를 출력하는 셈</li>
  <li>셔플링과 소팅 때문에 맵 태스크들에서의 원래 출력과 순서가 달라진다.</li>
  <li>대표적으로 같은 키를 갖는 레코드들끼리 모아서 처리해야할 필요가 없는 경우 많이 사용된다.</li>
</ul>

<h3 id="section-13">리듀스 기타</h3>
<ul>
  <li>리듀스에서 주의할 점은  인자로 넘어오는 밸류 리스트 (Iterable<v>)의 경우 한 번 밖에 스캔할 수 없다는 점입니다. 다시 스캔하려고 하면 에러가 발생한다.</v></li>
  <li>그 이유는 reduce메소드에 들어온 입력 레코드들이 메모리에 로드되기전에는 너무 클 수 있기 때문에 내부적으로 한 번만 스캔하도록 되어있다.</li>
  <li>리듀스 테스크를 만약 0으로 정해준다면 맵퍼들의 결과로만 결과가 출력이 되어 결과 파일은 part-m-xxxx로 나오게 될것이다.</li>
</ul>

<h2 id="section-14">출력 포맷</h2>
<p><img src="/assets/posts/res/2017-05-08/output-format.png" alt="output format" /></p>

<h3 id="textoutputformat">TextOutputFormat</h3>
<ul>
  <li>한 라인에서 키와 밸류는 tab문자로 구분된다.(KeyValueTextInputFormat)에 반대되는 개념 하지만 그렇다고해서 KeyValueTextOutputFormat이 존재하는건 아니다.</li>
  <li>결과파일 압축하기 job.setCompressOutput과 job.setOutputCompressClass를 사용하여 압축 방법과 여부를 설정할 수 있다.</li>
</ul>

<h3 id="sequencefileoutputformat">SequenceFileOutputFormat</h3>
<ul>
  <li>시퀀스 파일 포맷으로 출력파일을 쓸 때 사용함</li>
  <li>하둡의 여러잡을 이어서 실행할 경우 반드시 사용해야하는 출력포맷이다.</li>
  <li>
    <p>이 출력 포맷은 세 가지 압축 방식(Block, None, Record)를 지원하며 SequenceFileOutputFormat 클래스의 setOutputCompressionType 메소드를 통해 압축방식을 지정할 수 있다.(BLOCK, NONE, RECORD)</p>

    <table>
      <thead>
        <tr>
          <th>압축모드</th>
          <th>설명</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>BLOCK</td>
          <td>블록내의 레코드들을 같이 압축한다.</td>
        </tr>
        <tr>
          <td>NONE</td>
          <td>압축하지 않는다.</td>
        </tr>
        <tr>
          <td>RECORD</td>
          <td>레코드 별로 압축한다. 기본설정이 바로 레코드별 압축이다.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="mapfileoutputformat">MapFileOutputFormat</h3>
<ul>
  <li>출력을 맵 파일 형태로 만들어주는 출력포맷</li>
  <li>파일 기반의 맵으로 사실상 하나의 디렉토리로 구성되며 그 디렉토리 밑에 두 개의 파일이 존재한다.</li>
</ul>

<blockquote>
  <p>디렉토리 밑의 두 파일에 대한 설명
1. 하나는 맵의 데이터 파일로 모든 키와 벨류들이 들어간다. 키를 바탕으로 정렬된다.
2. 다른 하나는 인덱스 파일로 키들의 일부를 저장하는데 목적은 데이터 파일을 순차적으로 뒤지지 않도록 해주는것.</p>

  <p>순처적으로 뒤지지 않게하는게 왜 ?
- 순차적으로 뒤지지 않게 만들기 위해 키를 일정 간격으로 뽑아 내어서 저장해 둔다. (흔히 스킵테이블이라 한다.)
- 간격을 적당히 크게 하면 인덱스 파일의 크기가 작아지게된다.</p>

  <p>이것을 사용하기 위해서는 SequenceFileInputFormat 을 이용해야한다. (MapFileInputFormat은 존재하지 않는다.)</p>
</blockquote>

<h3 id="multipleoutput">MultipleOutput</h3>
<ul>
  <li>어떤 프로그램에서는 한 현태의 출력파일이 아니라 여러가지 형태의 서로 다른 출력 파일을 명시적으로 만들 수 있다.</li>
</ul>

<h2 id="mrunit-maven">MRUnit과 Maven</h2>

<h3 id="mrunit">MRUnit</h3>
<ul>
  <li>테스트 도구, JUnit과 같다.</li>
  <li>클라우데라에 의해 개발됨. 유닛 테스트 할 때 사용됨</li>
</ul>

<h3 id="section-15">유닛테스트</h3>
<ul>
  <li>소스 코드에서 일종의 단위별로 테스트 하는 것을 유닛 테스트라고 한다.</li>
  <li>큰 모듈을 테스트 하는것이 아니라 작은 클래스나 함수 단위에서 꼭 테스트 해보자는 것이다.</li>
  <li>유닛 테스트 코드를 가팅 추가하는것은 권장되고있고 강제가 될 때도 있다.</li>
  <li>if문의 개수당 테스트를 하기도 하며</li>
  <li>로직의 경로당 테스트를 전부 하느냐 하지않느냐에 따라 테스트 커버리지가 결정되기도 한다.</li>
</ul>

<h3 id="maven">Maven</h3>
<ul>
  <li>빌드 시스템,</li>
  <li>프로젝트 관리도구</li>
</ul>

<h2 id="section-16">그외 기타</h2>

<h3 id="job-tracker-web-interface">job tracker web interface</h3>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>mapred-site.xml</td>
          <td>mapred.job.tracker.http.address 의 값을 수정하면 url이나 포트를 변경할 수 있다.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="section-17">패키지 소스 코드 구분</h3>
<ul>
  <li>
    <p>레거시 코드 
 &gt; org.apache.hadoop.mapred</p>
  </li>
  <li>
    <p>최신 코드
 &gt; org.apache.hadoop.mapreduce</p>
  </li>
</ul>



        </section>

        <footer class="post-footer">

            <!-- Everything inside the #author tags pulls data from the author -->
            <!-- #author-->
        
            

            <section class="author">
                <h4><a href="/author/"></a></h4>

                
                <p>Read <a href="/author/">more posts</a> by this author.</p>
                
                <div class="author-meta">
                     
                    
                </div>
            </section> 
        
            <!-- /author  -->

            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="http://twitter.com/share?text=(스터디) 하둡.araboza - 5&amp;url=blog.drakejin.me%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-5"
                    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=blog.drakejin.me%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-5"
                    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=blog.drakejin.me%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-5"
                   onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>
            
            <!-- Add Disqus Comments -->
            
<div id="disqus_thread"></div>

<!--
<script>
(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');

    s.src = '//drake-jin-github-io/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


<div id="disqus_thread"></div>
-->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'drake-jin-github-io'; // required: replace example with your forum shortname
    var disqus_identifier = '/%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-5';
    var disqus_url = 'blog.drakejin.me/%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-5';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); 
        dsq.type = 'text/javascript'; 
        dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] 
         || 
         document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>

            
        </footer>

    </article>

</main>

<aside class="read-next">

    <!-- [[! next_post ]] -->
    
        <a class="read-next-story no-cover" href="/%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-6">
            <section class="post">
                <h2>(스터디) 하둡.araboza - 6</h2>
                <p>[데이터공작소] 하둡의 WordCount 예제가 아닌 약간의 응용을 해보는 예제를 체험합니다. ## 소스 위치 - ![Chapter06의...</p>
            </section>
        </a>
    
    <!-- [[! /next_post ]] -->
    <!-- [[! prev_post ]] -->
    
        <a class="read-next-story prev no-cover" href="/%EC%8A%A4%ED%84%B0%EB%94%94-%ED%95%98%EB%91%A1-4">
            <section class="post">
                <h2>(스터디) 하둡.araboza - 4</h2>
                <p>[데이터공작소] 하둡 스터디 자세한 내용은 소스에 주석을 달아 놓았습니다. 소스를 참고해주시기 바랍니다. Chapter 04 WordCount...</p>
            </section>
        </a>
    
    <!-- [[! /prev_post ]] -->
</aside>

<!-- /post -->


        <footer class="site-footer clearfix">
          <section class="copyright"><a href="/">데이터공작소</a> &copy; 2017</section>
          <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://github.com/biomadeira/jasper">Jasper</a></section>
        </footer>
    </div>
    <!-- [[! Ghost outputs important scripts and data with this tag ]] -->
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <!-- [[! The main JavaScript file for Casper ]] -->
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/assets/js/index.js"></script>

    <!-- Add Google Analytics  -->
        <!-- Google Analytics Tracking code -->
     <script>
	    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	    ga('create', 'UA-90708702-1', 'auto');
	    ga('send', 'pageview');

     </script>   
</body>
</html>
